#!/usr/bin/env node

// I am a wrapper around basic elastcidump
// I will source all indices from your elasticserach server and dump them out to .json and .mapping.json files
// I probably only work on *nix hosts
// dump --input must be a URL and --output must be a path on this system
// index --input must be a a path on this system --output must be URL

const argv = require('optimist').argv
const fs = require('fs')
const os = require('os')
const path = require('path')
const async = require('async')
const request = require('request')
const fork = require('child_process').fork
const _ = require('lodash')

const options = {}
let matchedIndexes = []
let working = 0
let complete = 0
let indexCounter = 0
let workTimeout

function unique (arr, keepLast) {
  return arr.filter((value, index, array) => keepLast ? array.indexOf(value, index + 1) < 0 : array.indexOf(value) === index)
}

const defaults = {
  debug: true,
  parallel: os.cpus().length,
  match: '^.*$',
  input: null,
  output: null,
  scrollTime: '10m',
  timeout: null,
  limit: 100,
  offset: 0,
  direction: 'dump', // default to dump
  'support-big-int': false,
  ignoreAnalyzer: false,
  ignoreData: false,
  ignoreMapping: false,
  ignoreSettings: false,
  ignoreTemplate: false,
  ignoreAlias: true,
  ignoreType: [],
  interval: 1000,
  prefix: '',
  suffix: '',
  transform: null,
  searchBody: null,
  cert: null,
  key: null,
  pass: null,
  ca: null,
  tlsAuth: false,
  'input-cert': null,
  'input-key': null,
  'input-pass': null,
  'input-ca': null,
  'output-cert': null,
  'output-key': null,
  'output-pass': null,
  'output-ca': null
}

for (let i in defaults) {
  options[i] = defaults[i]
  if (argv[i]) {
    options[i] = argv[i]
  }
  if (options[i] === 'true') { options[i] = true }
  if (options[i] === 'false') { options[i] = false }
  if (options[i] === 'null') { options[i] = null }
  if (i === 'interval' && _.isNumber(argv[i])) {
    // special case to handle value == 0
    options[i] = argv[i]
  }
}

_.split(options.ignoreType, ',').forEach(field => {
  const key = `ignore${_.upperFirst(field)}`
  if (_.has(options, key)) {
    options[key] = true
  }
})

const commonParams = [
  `--cert=${options.cert}`,
  `--key=${options.key}`,
  `--pass=${options.pass}`,
  `--ca=${options.ca}`,
  `--tlsAuth=${options.tlsAuth}`,
  `--input-cert=${options['input-cert']}`,
  `--input-key=${options['input-key']}`,
  `--input-pass=${options['input-pass']}`,
  `--input-ca=${options['input-ca']}`,
  `--output-cert=${options['output-cert']}`,
  `--output-key=${options['output-key']}`,
  `--output-pass=${options['output-pass']}`,
  `--output-ca=${options['output-ca']}`
]

const log = (type, message) => {
  if (type === 'debug') {
    if (options.debug === true) {
      message = `[debug] | ${message}`
    } else {
      return false
    }
  } else {
    message = `${new Date().toUTCString()} | ${message}`
  }
  console.log(message)
}

if (!options.input) { throw new Error('--input is required') }
if (!options.output) { throw new Error('--output is required') }
log('info', `We are performing : ${options.direction}`)
log('info', `options: ${JSON.stringify(options)}`)

const matchRegExp = new RegExp(options.match, 'i')
if (options.direction === 'dump') {
  if (!fs.existsSync(options.output)) { throw new Error('--output does not exist') }
  request.get(`${options.input}/_aliases`, (err, response) => {
    if (err) {
      log('err', err)
      process.exit()
    }
    response = JSON.parse(response.body)
    if (!Array.isArray(response)) {
      response = Object.keys(response)
    }
    matchedIndexes = response.filter(index => matchRegExp.test(index))

    dumpWork()
  })
}

if (options.direction === 'load') {
  if (!fs.existsSync(options.input)) { throw new Error('--input() does not exist') }
  fs.readdir(options.input, (err, data) => {
    if (err) {
      log('error', err)
      throw new Error('Something went wrong reading the list of files')
    }
    // log('info', data);
    matchedIndexes = data.map(value => value
        .replace('.mapping.json', '')
        .replace('.analyzer.json', '')
        .replace('.alias.json', '')
        .replace('.settings.json', '')
        .replace('.template.json', '')
        .replace('.json', '')).filter(item => matchRegExp.test(item))
    matchedIndexes = unique(matchedIndexes)
    log('info', `list of indexes${JSON.stringify(matchedIndexes)}`)

    loadWork()
  })
}

const dumpWork = () => {
  clearTimeout(workTimeout)
  if (complete === matchedIndexes.length) {
    log('info', ' dumping all done ')
    log('info', ' bye ')
    process.exit()
  } else if (working === options.parallel) {
    workTimeout = setTimeout(dumpWork, options.interval)
  } else {
    dump()
    workTimeout = setTimeout(dumpWork, options.interval)
  }
}

const loadWork = () => {
  clearTimeout(workTimeout)
  if (complete === matchedIndexes.length) {
    log('info', ' indexing all done ')
    log('info', ' bye ')
    process.exit()
  } else if (working === options.parallel) {
    workTimeout = setTimeout(loadWork, options.interval)
  } else {
    load()
    workTimeout = setTimeout(loadWork, options.interval)
  }
}

const dump = () => {
  working++
  const index = matchedIndexes[indexCounter]

  if (!index) {
    working--
    return
  }

  indexCounter++

  const input = `${options.input}/${encodeURIComponent(index).toLowerCase()}`
  const outputData = `${options.output}/${index}.json`
  const outputMapping = `${options.output}/${index}.mapping.json`
  const outputAnalyzer = `${options.output}/${index}.analyzer.json`
  const outputAlias = `${options.output}/${index}.alias.json`
  const outputSettings = `${options.output}/${index}.settings.json`
  const outputTemplate = `${options.output}/${index}.template.json`
  const jobs = []

  jobs.push(done => {
    if (options.ignoreTemplate) return done()
    log('info', `dumping ${input} to ${outputTemplate}`)

    const mappingSettings = fork(path.join(__dirname, 'elasticdump'), [
      '--type=template',
      `--input=${input}`,
      `--output=${outputTemplate}`
    ].concat(commonParams))

    mappingSettings.on('close', code => {
      if (code !== 0) {
        return done(new Error('CHILD PROCESS EXITED WITH ERROR.  Stopping process'))
      } else {
        return done()
      }
    })
  })

  jobs.push(done => {
    if (options.ignoreSettings) return done()
    log('info', `dumping ${input} to ${outputSettings}`)

    const mappingSettings = fork(path.join(__dirname, 'elasticdump'), [
      '--type=settings',
      `--input=${input}`,
      `--output=${outputSettings}`
    ].concat(commonParams))

    mappingSettings.on('close', code => {
      if (code !== 0) {
        return done(new Error('CHILD PROCESS EXITED WITH ERROR.  Stopping process'))
      } else {
        return done()
      }
    })
  })

  jobs.push(done => {
    if (options.ignoreMapping) return done()
    log('info', `dumping ${input} to ${outputMapping}`)

    const mappingChild = fork(path.join(__dirname, 'elasticdump'), [
      '--type=mapping',
      `--input=${input}`,
      `--output=${outputMapping}`
    ].concat(commonParams))

    mappingChild.on('close', code => {
      if (code !== 0) {
        return done(new Error('CHILD PROCESS EXITED WITH ERROR.  Stopping process'))
      } else {
        return done()
      }
    })
  })

  jobs.push(done => {
    if (options.ignoreAnalyzer) return done()
    log('info', `analyzer ${input} to ${outputAnalyzer}`)

    const analyzerChild = fork(path.join(__dirname, 'elasticdump'), [
      '--type=analyzer',
      `--input=${input}`,
      `--output=${outputAnalyzer}`
    ].concat(commonParams))

    analyzerChild.on('close', code => {
      if (code !== 0) {
        return done(new Error('CHILD PROCESS EXITED WITH ERROR.  Stopping process'))
      } else {
        return done()
      }
    })
  })

  jobs.push(done => {
    if (options.ignoreAlias) return done()
    log('info', `analyzer ${input} to ${outputAlias}`)

    const aliasChild = fork(path.join(__dirname, 'elasticdump'), [
      '--type=alias',
      `--input=${input}`,
      `--output=${outputAlias}`
    ].concat(commonParams))

    aliasChild.on('close', code => {
      if (code !== 0) {
        return done(new Error('CHILD PROCESS EXITED WITH ERROR.  Stopping process'))
      } else {
        return done()
      }
    })
  })

  jobs.push(done => {
    if (options.ignoreData) return done()
    log('info', `dumping ${input} to ${outputData}`)

    let _transform = []

    if (options.transform) {
      _transform = _.chain(options.transform)
          .castArray()
          .filter(_.negate(_.isEmpty))
          .map(t => {
            return `--transform=${t}`
          })
          .value()
    }

    const dataChild = fork(path.join(__dirname, 'elasticdump'), [
      '--type=data',
      `--input=${input}`,
      `--output=${outputData}`,
      `--scrollTime=${options.scrollTime}`,
      `--limit=${options.limit}`,
      `--offset=${options.offset}`,
      `--searchBody=${options.searchBody}`,
      `--prefix=${options.prefix}`,
      `--suffix=${options.suffix}`,
      `--support-big-int=${options['support-big-int']}`
    ].concat(_transform).concat(commonParams))

    dataChild.on('close', code => {
      if (code !== 0) {
        return done(new Error('CHILD PROCESS EXITED WITH ERROR.  Stopping process'))
      } else {
        return done()
      }
    })
  })

  async.series(jobs, error => {
    if (error) {
      log('error', error)
      process.exit(1)
    } else {
      working--
      complete++
    }
  })
}

const load = () => {
  working++
  const index = matchedIndexes[indexCounter]

  if (!index) {
    working--
    return
  }

  log('info', `Working on ${index}`)

  indexCounter++

  const output = `${options.output}/${encodeURIComponent(index).toLowerCase()}`
  const inputData = `${options.input}/${index}.json`
  const inputMapping = `${options.input}/${index}.mapping.json`
  const inputAnalyzer = `${options.input}/${index}.analyzer.json`
  const inputAlias = `${options.input}/${index}.alias.json`
  const inputSettings = `${options.input}/${index}.settings.json`
  const inputTemplate = `${options.input}/${index}.template.json`

  const jobs = []

  jobs.push(done => {
    if (options.ignoreTemplate) return done()
    log('info', `indexing template ${inputTemplate} to ${output}`)

    const templateChild = fork(path.join(__dirname, 'elasticdump'), [
      '--type=template',
      `--input=${inputTemplate}`,
      `--output=${output}`
    ].concat(commonParams))

    templateChild.on('close', code => {
      if (code !== 0) {
        return done(new Error('CHILD PROCESS EXITED WITH ERROR.  Stopping process'))
      } else {
        return done()
      }
    })
  })

  jobs.push(done => {
    if (options.ignoreSettings) return done()
    log('info', `indexing settings ${inputSettings} to ${output}`)

    const settingsChild = fork(path.join(__dirname, 'elasticdump'), [
      '--type=settings',
      `--input=${inputSettings}`,
      `--output=${output}`
    ].concat(commonParams))

    settingsChild.on('close', code => {
      if (code !== 0) {
        return done(new Error('CHILD PROCESS EXITED WITH ERROR.  Stopping process'))
      } else {
        return done()
      }
    })
  })

  jobs.push(done => {
    if (options.ignoreAnalyzer) return done()
    log('info', `indexing analyzer ${inputAnalyzer} to ${output}`)

    const analyzerChild = fork(path.join(__dirname, 'elasticdump'), [
      '--type=analyzer',
      `--input=${inputAnalyzer}`,
      `--output=${output}`
    ].concat(commonParams))

    analyzerChild.on('close', code => {
      if (code !== 0) {
        return done(new Error('CHILD PROCESS EXITED WITH ERROR.  Stopping process'))
      } else {
        return done()
      }
    })
  })

  jobs.push(done => {
    if (options.ignoreMapping) return done()
    log('info', `indexing mapping ${inputMapping} to ${output}`)

    const mappingChild = fork(path.join(__dirname, 'elasticdump'), [
      '--type=mapping',
      `--input=${inputMapping}`,
      `--output=${output}`
    ].concat(commonParams))

    mappingChild.on('close', code => {
      if (code !== 0) {
        return done(new Error('CHILD PROCESS EXITED WITH ERROR.  Stopping process'))
      } else {
        return done()
      }
    })
  })

  jobs.push(done => {
    if (options.ignoreAlias) return done()
    log('info', `indexing alias ${inputAlias} to ${output}`)

    const aliasChild = fork(path.join(__dirname, 'elasticdump'), [
      '--type=alias',
      `--input=${inputAlias}`,
      `--output=${output}`
    ].concat(commonParams))

    aliasChild.on('close', code => {
      if (code !== 0) {
        return done(new Error('CHILD PROCESS EXITED WITH ERROR.  Stopping process'))
      } else {
        return done()
      }
    })
  })

  jobs.push(done => {
    if (options.ignoreData) return done()
    log('info', `indexing data ${inputData} to ${output}`)

    let _transform = []

    if (options.transform) {
      _transform = _.chain(options.transform)
        .castArray()
        .filter(_.negate(_.isEmpty))
        .map(t => {
          return `--transform=${t}`
        })
        .value()
    }

    const dataChild = fork(path.join(__dirname, 'elasticdump'), [
      '--type=data',
      `--input=${inputData}`,
      `--output=${output}`,
      `--scrollTime=${options.scrollTime}`,
      `--timeout=${options.timeout}`,
      `--limit=${options.limit}`,
      `--offset=${options.offset}`,
      `--prefix=${options.prefix}`,
      `--suffix=${options.suffix}`,
      `--support-big-int=${options['support-big-int']}`
    ].concat(_transform).concat(commonParams))

    dataChild.on('close', code => {
      if (code !== 0) {
        return done(new Error('CHILD PROCESS EXITED WITH ERROR.  Stopping process'))
      } else {
        return done()
      }
    })
  })

  async.series(jobs, error => {
    if (error) {
      log('error', error)
      process.exit(1)
    } else {
      working--
      complete++
    }
  })
}
